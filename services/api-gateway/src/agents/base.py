# SPDX-License-Identifier: Apache-2.0
"""File: services/api-gateway/src/agents/base.py

Project: astradesk
Pakage: api-gateway

Author: Siergej Sobolewski
Since: 2025-10-29

Abstract base class (ABC) and lifecycle contract for all agents.

Encapsulates the end-to-end execution loop (plan → act → reflect → replan) while
delegating strategy-specific behavior to subclasses via well-defined hooks.
Integrates Intent Graph for dynamic planning, self-reflection for quality evaluation,
OPA for governance, and OTel for observability.

Features for Production:
- Configurable thresholds, max reflections, and timeouts
- Cycle detection in Intent Graph to prevent infinite loops
- Robust JSON parsing in reflection with fallbacks
- Error retries in planning and execution
- OTel spans with detailed attributes and events

"""

from __future__ import annotations

import asyncio
import json
import logging
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Tuple

import networkx as nx  # For Intent Graph (DiGraph with nodes/edges)
from opentelemetry import trace  # AstraOps/OTel tracing
from pydantic import BaseModel
from model_gateway.llm_planner import LLMPlanner
from runtime.planner import  KeywordPlanner
from runtime.memory import Memory, Memory
from runtime.models import ToolCall
from runtime.policy import policy as opa_policy
from runtime.rag import RAG
from runtime.registry import ToolRegistry

logger = logging.getLogger(__name__)

# Configurable production settings
REFLECTION_THRESHOLD = 0.7
MAX_REFLECTIONS = 3
MAX_GRAPH_NODES = 20
PLANNING_RETRY_COUNT = 2
TOOL_TIMEOUT_SEC = 30.0
PLANNING_TIMEOUT_SEC = 10.0


class PlanStep(BaseModel):
    """Pydantic model for a single step in the plan."""

    name: str
    arguments: Dict[str, Any]


class Plan(BaseModel):
    """Pydantic model for the full plan generated by planner."""

    steps: List[PlanStep]


class BaseAgent(ABC):
    """Abstract base class for all agents in AstraDesk.
    Provides common structure for dynamic planning with Intent Graph, execution,
    contextual info retrieval, self-reflection, and OPA governance.
    """  # noqa: D205

    def __init__(
        self,
        tools: ToolRegistry,
        memory: Memory,
        planner: KeywordPlanner,
        rag: RAG,
        llm_planner: LLMPlanner,  # For reflection
        agent_name: str,
    ) -> None:
        """Initializes the base agent.

        Args:
            tools: Registry of available tools.
            memory: Memory layer for auditing and storage.
            planner: Planner for generating execution plans.
            rag: RAG system for knowledge retrieval.
            llm_planner: LLM planner used for reflection and scoring.
            agent_name: Name of the agent for identification.

        """  # noqa: D401
        self.tools = tools
        self.memory = memory
        self.planner = planner
        self.rag = rag
        self.llm_planner = llm_planner
        self.opa_policy = opa_policy  # Assuming global policy facade
        self.agent_name = agent_name
        self.name = agent_name
        self.tracer = trace.get_tracer(__name__)  # OTel tracer

    @abstractmethod
    async def _get_contextual_info(
        self, query: str, invoked_tools: List[ToolCall]
    ) -> List[str]:
        """Implementation of contextual strategy for the agent.

        Args:
            query: Original user query.
            invoked_tools: List of successfully invoked tools.

        Returns:
            List of context snippets from RAG or empty list.

        """
        raise NotImplementedError("Subclass must implement _get_contextual_info")

    async def _reflect(self, step_result: str, query: str) -> float:
        """Self-reflection: Evaluate step quality using LLM.

        Prompt:
        Query: "{query}"
        Result: "{step_result}"
        On a scale of 0.0 to 1.0, how well does this result address the query? JSON: {"score": 0.85}

        Args:
            step_result: Result from tool execution.
            query: Original user query.

        Returns:
            Score (0.0 to 1.0) indicating quality.

        """
        with self.tracer.start_as_current_span("agent_reflect"):
            system_prompt = (
                "Evaluate how well the result addresses the query. "
                "Return JSON {'score': float(0.0-1.0)}. No explanations."
            )
            user_prompt = f"Query: \"{query}\"\nResult: \"{step_result}\""

            try:
                raw_response = await self.llm_planner.chat(
                    [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
                    params={"max_tokens": 50, "temperature": 0.0}
                )
                # Robust JSON parsing
                raw = raw_response.strip()
                if raw.startswith("{") and raw.endswith("}"):
                    data = json.loads(raw)
                    return max(0.0, min(1.0, float(data.get("score", 0.5))))
                else:
                    raise ValueError("Invalid JSON response")
            except Exception as e:
                logger.warning(f"Reflection failed: {e}")
                return 0.5  # Default medium score on error

    async def run(
        self, query: str, context: Dict[str, Any]
    ) -> Tuple[str, List[ToolCall]]:
        """Runs the main execution loop of the agent with Intent Graph, reflection, and OPA.

        Workflow:
        1. Generate initial plan with retries.
        2. Build Intent Graph (DiGraph).
        3. For each step: OPA check → execute with timeout → reflect → replan if score low (with max limits).
        4. Get contextual info → finalize → store.

        Args:
            query: User query.
            context: Contextual dictionary including 'claims' and 'request_id'.

        Returns:
            Tuple containing (final_text_response, list_of_invoked_tools).
        """
        with self.tracer.start_as_current_span("agent_run") as span:
            span.set_attribute("agent_name", self.agent_name)
            span.set_attribute("query", query)

            # Generate initial plan with retries
            initial_plan = None
            for attempt in range(PLANNING_RETRY_COUNT + 1):
                try:
                    initial_plan = await asyncio.wait_for(self.planner.make_plan(query), timeout=PLANNING_TIMEOUT_SEC)
                    break
                except asyncio.TimeoutError:
                    logger.warning(f"Planning timeout on attempt {attempt}")
                except Exception as e:
                    logger.warning(f"Planning failed on attempt {attempt}: {e}")
                if attempt < PLANNING_RETRY_COUNT:
                    await asyncio.sleep(1)  # Simple backoff
            if initial_plan is None:
                raise RuntimeError("Failed to generate initial plan after retries")

            # Build Intent Graph
            intent_graph = nx.DiGraph()
            for i, step in enumerate(initial_plan.steps):
                intent_graph.add_node(i, step=step)
                if i > 0:
                    intent_graph.add_edge(i - 1, i)  # Sequential edges

            tool_results: List[str] = []
            invoked_tools: List[ToolCall] = []
            reflection_count = 0

            # Traverse graph with queue, handling replans
            queue = list(intent_graph.nodes)
            idx = 0
            while idx < len(queue):
                node = queue[idx]

                # Check graph limits and cycles
                if len(intent_graph.nodes) > MAX_GRAPH_NODES:
                    raise RuntimeError("Graph size exceeded max nodes")
                if nx.has_cycles(intent_graph):  # type: ignore[attr-defined]
                    raise RuntimeError("Cycle detected in Intent Graph")

                step = intent_graph.nodes[node]["step"]
                tool_call = ToolCall(name=step.name, arguments=step.arguments)

                # OPA governance with flexible wrapper
                opa_payload = {"action": step.name, "claims": context.get("claims")}
                try:
                    await _authorize(self.opa_policy, "tools.invoke", context.get("claims"), opa_payload)
                except Exception as e:
                    span.record_exception(e)
                    tool_results.append(f"Authorization error: {str(e)}")
                    invoked_tools.append(tool_call)
                    idx += 1
                    continue

                # Execute with timeout
                try:
                    result = await asyncio.wait_for(
                        self.tools.execute(step.name, claims=context.get("claims"), **step.arguments),
                        timeout=TOOL_TIMEOUT_SEC
                    )
                except asyncio.TimeoutError:
                    result = "Timeout during execution"
                except Exception as e:
                    result = f"Error: {str(e)}"

                tool_results.append(result)
                invoked_tools.append(tool_call)

                # Self-reflection
                score = await self._reflect(result, query)
                reflection_count += 1
                span.set_attribute("reflection_count", reflection_count)
                span.set_attribute(f"step_{node}_score", score)

                if score < REFLECTION_THRESHOLD and reflection_count < MAX_REFLECTIONS:
                    span.add_event("Replanning due to low score")
                    new_plan = await self.planner.replan(query, tool_results)
                    # Append new steps to graph and queue
                    new_start = len(intent_graph.nodes)
                    for j, new_step in enumerate(new_plan.steps):
                        new_node = new_start + j
                        intent_graph.add_node(new_node, step=new_step)
                        intent_graph.add_edge(node, new_node)
                        queue.append(new_node)
                idx += 1

            # Get contextual info and finalize
            contextual_info = await self._get_contextual_info(query, invoked_tools)
            final_response = self.planner.finalize(query, tool_results, contextual_info)
            await self.memory.store_dialogue(self.agent_name, query, final_response, context)
            return final_response, invoked_tools
